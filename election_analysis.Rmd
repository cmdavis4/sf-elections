---
title: "R Notebook"
output: html_notebook
---

```{r setup}
rm(list=ls())
library(scales)
library(ggplot2)
library(gridExtra)
```

```{r}

exclusions <- c()

raw.df <- NULL
measure.names <- c()
for(f in list.files('./data/derived_data')){
  # For now we only want to parse the files that are election data that is not explicitly excluded above
  if(startsWith(f, 'precinct_summary_') & !(f %in% exclusions)){
    df <- read.csv(paste('./data/derived_data/', f, sep=''))
    prefix <- tolower(strsplit(f, '-')[[1]][2])
    prefix <- gsub("^[[:space:]]", "", prefix)  # Strip leading whitespace
    prefix <- gsub("[[:space:]]", "_", prefix)  # Replace spaces with underscores
    prefix <- gsub("[^[:alnum:]&^\\_]", "", prefix)  # Drop non-alphanumeric characters (except underscores)
    prefix <- substr(prefix, start=1, stop=nchar(prefix)-3)  # Drop the "csv" from the end
    measure.names <- c(measure.names, prefix)
    names(df)[names(df)!='precinctid'] <- paste(prefix, names(df)[names(df)!='precinctid'], sep='_')
    if(is.null(raw.df)){
      raw.df <- df
    }
    else{
      raw.df <- merge(raw.df, df, by='precinctid', all.x=TRUE)
    }
  }
}
```

### Feature creation

Now we need to do feature creation and cleaning. We don't care about over vote on its own, so we'll certainly drop that. In precincts where there was no over vote for a certain binary measure (unlikely but possible), this would still be overdefined (i.e. yes + no + under = ballots cast), so we'll drop under votes as well. We'll then normalize the yes votes as yes/(yes+no), which we'll call "yes_of_accepted", and drop the no votes. For races with people, we'll drop write-in since I'd be shocked if that had any useful information, and then normalize the rest of the votes as candidate / ballots_cast. For every measure we'll also create a feature calculated and ballots cast / registration, called which we'll call "turnout"

To make sure that dropping over votes is ok, let's look at the average percent of ballots cast that were over votes:

```{r}
over.vote.percents <- c()
for (measure.name in measure.names){
  voters <- raw.df[!is.na(raw.df[, paste(measure.name, 'over_vote', sep='_')]),]
  over.vote <- voters[, paste(measure.name, 'over_vote', sep='_')]
  ballots.cast <- voters[, paste(measure.name, 'ballots_cast', sep='_')]
  over.vote.percents <- c(over.vote.percents, sum(over.vote) / sum(ballots.cast))
}
# We need to exclude State Senator in District 13, because no one in SF voted in it:
over.vote.percents <- over.vote.percents[!is.na(over.vote.percents)]
```

On average, `r percent(mean(over.vote.percents))` of the ballots cast for a measure were over votes, so we don't need to worry too much about their interpretation.

Now let's transform the features for all of the measures as discussed above:

```{r}
features.df <- raw.df
for (measure.name in measure.names){
  features <- names(features.df)[grepl(measure.name, names(features.df))]
  if(paste(measure.name, 'yes', sep='_') %in% features){
    features.df[, paste(measure.name, 'yes_of_accepted', sep='_')] <- (
      features.df[, paste(measure.name, 'yes', sep='_')] / (
        features.df[, paste(measure.name, 'yes', sep='_')] + features.df[, paste(measure.name, 'no', sep='_')]
        )
      )
  }
  else{
    for (feature in features){
      if(!(
        endsWith(feature, 'under_vote') |
        endsWith(feature, 'over_vote') |
        endsWith(feature, 'ballots_cast') |
        endsWith(feature, 'registration')
      )){
        features.df[, feature] <- features.df[, feature] / features.df[, paste(measure.name, 'ballots_cast', sep='_')]
      }
    }
  }
  features.df[, paste(measure.name, 'turnout', sep='_')] <- (
    features.df[, paste(measure.name, 'ballots_cast', sep='_')] / features.df[, paste(measure.name, 'registration', sep='_')]
    )
  features.df <- features.df[, !names(features.df) %in% c(
    paste(measure.name, 'no', sep='_'),
    paste(measure.name, 'yes', sep='_'),
    paste(measure.name, 'writein', sep='_'),
    paste(measure.name, 'under_vote', sep='_'),
    paste(measure.name, 'over_vote', sep='_'),
    paste(measure.name, 'ballots_cast', sep='_'),
    paste(measure.name, 'precincts', sep='_'),
    paste(measure.name, 'registration', sep='_')
  )]
}
```

## District 5 Supervisor

A race near and dear to me. Let's start by just checking out what the Dean vote percent correlates with:

```{r}
# Filter to D5
d5 <- features.df[!is.na(features.df$board_of_supervisors_district_5_turnout),]
d5 <- d5[, !apply(is.na(d5), 2, any)]
d5.subset <- d5[, sapply(names(d5), function(x) !endsWith(x, 'turnout') & x != 'precinctid')]
```

```{r}
cor.flat <- function(df){
  cor.matrix <- cor(df)
  diag(cor.matrix) <- 0
  cor.matrix[lower.tri(cor.matrix)] <- 0
  cor.matrix <- as.data.frame(as.table(cor.matrix))
  names(cor.matrix) <- c("First.Variable", "Second.Variable","Correlation")
  cor.matrix[order(abs(cor.matrix$Correlation),decreasing=T),]
}

dean.cor <- cor.flat(d5.subset)
dean.cor <- dean.cor[(grepl('dean_preston', dean.cor$First.Variable))|(grepl('dean_preston', dean.cor$Second.Variable)),]
dean.cor[!grepl('dean_preston', dean.cor$First.Variable), c('First.Variable', 'Second.Variable')] <- dean.cor[!grepl('dean_preston', dean.cor$First.Variable), c('Second.Variable', 'First.Variable')]
dean.cor <- dean.cor[, names(dean.cor) != 'First.Variable']
dean.cor
```

Nothing too surprising or counterintuitive in the top couple - London correlating with Dean so strongly obviously makes sense (and would be perfectly correlated if not for writein votes), and, as noted before, a precinct's choice of supervisor is most strongly correlated with whether or not it wanted mandatory condom use in porn (State Prop 60), hilariously enough. Let's look at plots of the top 4 (excluding London):

```{r}
# Let's drop London, since that's useless
plot.data <- d5.subset[, c(as.character(dean.cor[2:5, 'Second.Variable']), 'board_of_supervisors_district_5_dean_preston')]
plots <- lapply(colnames(plot.data)[!grepl('dean_preston', colnames(plot.data))], function(column) {
  rs <- percent(summary(lm(plot.data[, 'board_of_supervisors_district_5_dean_preston']~plot.data[,column]))$r.squared)
  ggplot(data=plot.data, aes_string(x=column, y='board_of_supervisors_district_5_dean_preston')) +
    geom_point() +
    stat_smooth(method="lm") + ylab('% Dean of Accepted') +
    annotate("text", x=-Inf, y=-Inf, vjust=0, hjust=0, label=paste('R^2=', rs, sep=''))
})
do.call(grid.arrange, list(grobs=plots, ncol=2, top="Strongest Dean Correlations"))
```

## Towards a metric of "progressiveness"

An interesting metric to work towards would be a vector (or, less ideally, couple of vectors) to represent the "progressiveness" of a precinct. An approach to this that would be more mathematically sound than manually cooking up some vector based on knowledge of local politics is the following:
* Do dimensionality reduction using PCA
* Find the principal components that correlate most strongly with some measure where there was a clear progressive/moderate split; the D5 supervisor race lends itself nicely to this (though then this would only apply to D5)
* Test whether these vectors (or, ideally, this vector) also explain a good chunk of the variance in other measures where there's a clear progressive/moderate split

First let's try this just for the D5 supervisor race to see if we can predict a precinct's supervisor preference with as few PC's as possible:

```{r}
# Set tolerance to .1 to cut out the most useless components
pca <- prcomp(d5.subset[!grepl('board_of_supervisors_district_5', names(d5.subset))], center=TRUE, scale=TRUE, tol=.1)
pca.df <- as.data.frame(pca$x)
pca.df$board_of_supervisors_district_5_dean_preston <- d5.subset$board_of_supervisors_district_5_dean_preston
pca.cor <- cor.flat(pca.df)
pca.cor <- pca.cor[grepl('dean_preston', pca.cor$First.Variable)|grepl('dean_preston', pca.cor$Second.Variable), ]
pca.cor[grepl('dean_preston', pca.cor$Second.Variable), c('First.Variable', 'Second.Variable')] <- pca.cor[grepl('dean_preston', pca.cor$Second.Variable), c('Second.Variable', 'First.Variable')]
pca.cor
```

Now let's just try a multiple linear regression on the top couple:

```{r}
mean.residuals <- c()
fits <- list()
ns <- 1:10
for(n in ns){
  pcs <- as.character(pca.cor[1:n, 'Second.Variable'])
  pca.subset <- pca.df[, c('board_of_supervisors_district_5_dean_preston', pcs)]
  fit <- lm(board_of_supervisors_district_5_dean_preston ~ ., data=pca.subset)
  mean.residuals <- c(mean.residuals, mean(abs(fit$residuals)))
  fits[[n]] <- fit
}

do.call(anova, fits)

p1 <- ggplot(data=data.frame(x=ns, y=mean.residuals), aes(x=x, y=y)) +
  geom_line() +
  xlab('Included principal components') +
  ylab('Mean residual magnitude') +
  scale_x_continuous(breaks=ns) +
  scale_y_continuous(breaks=seq(from=0, to=.04, by=.005))

p2 <- ggplot(data=data.frame(x=ns, y=sapply(fits, function(x) summary(x)$r.squared)), aes(x=x, y=y)) +
  geom_line() +
  xlab('Included principal components') +
  ylab('R^2') +
  scale_x_continuous(breaks=ns)

grid.arrange(p1, p2, top="PCA of Dean Preston vote by precinct")

```

So we can explain `r percent(summary(fits[[3]])$r.squared)` of the variation in Dean's percent vote by precinct with the 3 most explanatory principal components. Let's look into what these principal components are:

```{r}
pca.names <- pca.cor[1:3, 'Second.Variable']

dummy <- lapply(pca.names, function(x){
  print(as.character(x))
  print(as.table(pca$rotation[, x][order(abs(pca$rotation[, x]), decreasing=TRUE)][1:20]))
})

# dean.pca.rotation <- data.frame(lapply(pca.names, function(x){
#   names(pca$rotation[, x][order(abs(pca$rotation[, x]), decreasing=TRUE)][1:10])
# }))
# colnames(dean.pca.rotation) <- pca.names
# dean.pca.rotation
```

I'll now attempt to interpret these using a qualitative knowledge of city politics/the polarization around a given measure:

###PC1: General "Conservativeness""
In a *very* rough sense, PC1 corresponds to something like **general "conservativness"** - things like keeping the death penalty, maintaining the criminalization of marijuana, voting for the nefarious Prop Q which was essentially a symbolic middle finger to homeless people, etc. This interpretation holds fairly well for all 10 of the top propositions.

###PC3: Anti-Corporate/Anti-Establishment Sentiment
PC5 is a little harder to interpet, as there are some conflicting components here as far as cleavage along traditional left/right political lines. At first one might think this is the progressive democrat contingent, since voting for Preston Picus and not for Nancy Pelosi were the single most important features of this PC, but the ballot measures (and positive coefficient for Gary Johnson) complicate that interpretation. I suspect this principal component represents something more like **anti-establishment sentiment**. From the perspective of candidates, we see that this PC voted for Dean Preston, Preston Picus, Jill Stein, and Gary Johnson, and emphatically NOT for London Breed, Nancy Pelosi, or Hillary Clinton, which can pretty uncontroversially be classified as an insurgent/establishment binary. However, from the point of view of ballot measures, this PC also voted against school bonds, taxes, condoms in porn, and gun control, and for restrictions on campaign contributions from lobbyists and transparency in the state legislature. I believe this feature can then be interpreted as distrust of the establishment, both political and corporate, and especially the intersection of the two. These may be small-government folks, some libertarians (as we see from the Gary Johnson coefficient,) or just people whose defining political ideology is less a left/right persepctive than it is an antagonistic stance towards a corrupt political establishment.

*\*\*Note that the school board/community college members here were a little all over the place since you could vote for about half of the field, so I didn't belabor them, but they roughly match the above interpretation.*


~~The high positive coefficient of voting for Jill Stein and negative coefficient of voting for Hillary Clinton is very telling, and might lead one to believe that this is the Bernie crowd, but some of the other important features complicate this interpretation. State prop 51 was somewhat contentious among progressives, but voting against it is the most important feature of this component, which makes the Bernie interpretation hard to swallow. Overall the character of this component is to vote far left on *people* (yes on Jill Stein and Preston Picus, no on Hillary Clinton [Rob Geller received such a small portion of the popular vote that I'm hesitant to say anything about him in this context]), but to actually vote *right* in a "small government" sense on ballot measures (no on gun control and basically anything involving government spending.) Interpeting this one is much more of an art than a science, but a first guess would be that this is folks who **are generally distrustful of both corporations, the government, and especially the intersection of the two in "corporate" politicians**. This explains their aversion to gun control, government spending, Hillary Clinton, Nancy Pelosi, and London Breed; and their embrace of Jill Stein, Preston Picus, and Dean Preston, none of whom took corporate money.~~

##PC3: Education

