---
title: "R Notebook"
output: html_notebook
---

```{r setup, echo=FALSE}
rm(list=ls())
library(scales)
library(ggplot2)
library(gridExtra)
```

```{r echo=FALSE}

exclusions <- c()

raw.df <- NULL
measure.names <- c()
for(f in list.files('./data/derived_data')){
  # For now we only want to parse the files that are election data that is not explicitly excluded above
  if(startsWith(f, 'precinct_summary_') & !(f %in% exclusions)){
    df <- read.csv(paste('./data/derived_data/', f, sep=''))
    prefix <- tolower(strsplit(f, '-')[[1]][2])
    prefix <- gsub("^[[:space:]]", "", prefix)  # Strip leading whitespace
    prefix <- gsub("[[:space:]]", "_", prefix)  # Replace spaces with underscores
    prefix <- gsub("[^[:alnum:]&^\\_]", "", prefix)  # Drop non-alphanumeric characters (except underscores)
    prefix <- substr(prefix, start=1, stop=nchar(prefix)-3)  # Drop the "csv" from the end
    measure.names <- c(measure.names, prefix)
    names(df)[names(df)!='precinctid'] <- paste(prefix, names(df)[names(df)!='precinctid'], sep='_')
    if(is.null(raw.df)){
      raw.df <- df
    }
    else{
      raw.df <- merge(raw.df, df, by='precinctid', all.x=TRUE)
    }
  }
}
```

### Feature creation

Now we need to do feature creation and cleaning. We don't care about over vote on its own, so we'll certainly drop that. In precincts where there was no over vote for a certain binary measure (unlikely but possible), this would still be overdefined (i.e. yes + no + under = ballots cast), so we'll drop under votes as well. We'll then normalize the yes votes as yes/(yes+no), which we'll call "yes_of_accepted", and drop the no votes. For races with people, we'll drop write-in since I'd be shocked if that had any useful information, and then normalize the rest of the votes as candidate / ballots_cast. For every measure we'll also create a feature calculated and ballots cast / registration, called which we'll call "turnout"

To make sure that dropping over votes is ok, let's look at the average percent of ballots cast that were over votes:

```{r echo=FALSE}
over.vote.percents <- c()
for (measure.name in measure.names){
  voters <- raw.df[!is.na(raw.df[, paste(measure.name, 'over_vote', sep='_')]),]
  over.vote <- voters[, paste(measure.name, 'over_vote', sep='_')]
  ballots.cast <- voters[, paste(measure.name, 'ballots_cast', sep='_')]
  over.vote.percents <- c(over.vote.percents, sum(over.vote) / sum(ballots.cast))
}
# We need to exclude State Senator in District 13, because no one in SF voted in it:
over.vote.percents <- over.vote.percents[!is.na(over.vote.percents)]
```

On average, `r percent(mean(over.vote.percents))` of the ballots cast for a measure were over votes, so we don't need to worry too much about their interpretation.

Now let's transform the features for all of the measures as discussed above:

```{r echo=FALSE}
features.df <- raw.df
for (measure.name in measure.names){
  features <- names(features.df)[grepl(measure.name, names(features.df))]
  if(paste(measure.name, 'yes', sep='_') %in% features){
    features.df[, paste(measure.name, 'yes_of_accepted', sep='_')] <- (
      features.df[, paste(measure.name, 'yes', sep='_')] / (
        features.df[, paste(measure.name, 'yes', sep='_')] + features.df[, paste(measure.name, 'no', sep='_')]
        )
      )
  }
  else{
    for (feature in features){
      if(!(
        endsWith(feature, 'under_vote') |
        endsWith(feature, 'over_vote') |
        endsWith(feature, 'ballots_cast') |
        endsWith(feature, 'registration')
      )){
        features.df[, feature] <- features.df[, feature] / features.df[, paste(measure.name, 'ballots_cast', sep='_')]
      }
    }
  }
  features.df[, paste(measure.name, 'turnout', sep='_')] <- (
    features.df[, paste(measure.name, 'ballots_cast', sep='_')] / features.df[, paste(measure.name, 'registration', sep='_')]
    )
  features.df <- features.df[, !names(features.df) %in% c(
    paste(measure.name, 'no', sep='_'),
    paste(measure.name, 'yes', sep='_'),
    paste(measure.name, 'writein', sep='_'),
    paste(measure.name, 'under_vote', sep='_'),
    paste(measure.name, 'over_vote', sep='_'),
    paste(measure.name, 'ballots_cast', sep='_'),
    paste(measure.name, 'precincts', sep='_'),
    paste(measure.name, 'registration', sep='_')
  )]
}
```

# Understanding the District 5 Supervisor Race

A race near and dear to me. Let's start by just checking out what the Dean vote percent correlates with:

```{r echo=FALSE}
# Filter to D5
d5 <- features.df[!is.na(features.df$board_of_supervisors_district_5_turnout),]
d5 <- d5[, !apply(is.na(d5), 2, any)]
d5.subset <- d5[, sapply(names(d5), function(x) !endsWith(x, 'turnout') & x != 'precinctid')]
```

```{r echo=FALSE}
cor.flat <- function(df){
  cor.matrix <- cor(df)
  diag(cor.matrix) <- 0
  cor.matrix[lower.tri(cor.matrix)] <- 0
  cor.matrix <- as.data.frame(as.table(cor.matrix))
  names(cor.matrix) <- c("First.Variable", "Second.Variable","Correlation")
  cor.matrix[order(abs(cor.matrix$Correlation),decreasing=T),]
}

dean.cor <- cor.flat(d5.subset)
dean.cor <- dean.cor[(grepl('dean_preston', dean.cor$First.Variable))|(grepl('dean_preston', dean.cor$Second.Variable)),]
dean.cor[!grepl('dean_preston', dean.cor$First.Variable), c('First.Variable', 'Second.Variable')] <- dean.cor[!grepl('dean_preston', dean.cor$First.Variable), c('Second.Variable', 'First.Variable')]
dean.cor <- dean.cor[, names(dean.cor) != 'First.Variable']
dean.cor
```

Nothing too surprising or counterintuitive in the top couple - London correlating against Dean so strongly obviously makes sense, and, as noted before, a precinct's choice of supervisor is most strongly correlated with whether or not it wanted mandatory condom use in porn (State Prop 60), hilariously enough. Let's look at plots of the top 4 (excluding London):

```{r echo=FALSE}
# Let's drop London, since that's useless
plot.data <- d5.subset[, c(as.character(dean.cor[2:5, 'Second.Variable']), 'board_of_supervisors_district_5_dean_preston')]
plots <- lapply(colnames(plot.data)[!grepl('dean_preston', colnames(plot.data))], function(column) {
  rs <- percent(summary(lm(plot.data[, 'board_of_supervisors_district_5_dean_preston']~plot.data[,column]))$r.squared)
  ggplot(data=plot.data, aes_string(x=column, y='board_of_supervisors_district_5_dean_preston')) +
    geom_point() +
    stat_smooth(method="lm") + ylab('% Dean of Accepted') +
    annotate("text", x=-Inf, y=-Inf, vjust=0, hjust=0, label=paste('R^2=', rs, sep=''))
})
do.call(grid.arrange, list(grobs=plots, ncol=2, top="Strongest Dean Correlations"))
```

##Breaking it down

Doing a series of linear regressions against other ballot measures doesn't get us very far in understanding the factors underlying the results of the District 5 supervisor race. The State Prop 60 (mandatory condom use in porn) result correlating so strongly with the Dean vote hilarious and weird, but not super surprising - there's probably a latent age variable underlying it. Tom Temprano essentially ran with Dean, basically every voter guide that endorsed Dean also endorsed Jane Kim, and, while I wouldn't have guessed Prop N (non-citizen voting in school board elections) would be number 4, it also obviously isn't suprising when viewed from the traditional left/right political paradigm.

We want to essentially understand the latent variables underlying the election results. The way to get to latent variables, in a formal sense, would be something like factor analysis or partial least squares regression. However, we're going to use principal components analysis. Why? I'm more familiar with it, and it almost always gives a very similar result to factor analysis.

Our approach here will essentially be a home-cooked version of principal components regression:

* Do dimensionality reduction using PCA
* Find the principal components that correlate most strongly with some measure in which we are interested (first, the district 5 supervisor race)
* Check how much these of the variance in our response (Dean) the PCs explain when used in a multiple linear regression, and choose how many to keep for the sake of parsimony
* Test whether those same principal components also explain a good chunk of the variance in other measures where there's a clear progressive/moderate split

As mentioned above, we'll first try this on the D5 supervisor race because I'm personally attached to it and I wanna know what happened, damnit!

```{r echo=FALSE}
# Set tolerance to .1 to cut out the most useless components
pca <- prcomp(d5.subset[!grepl('board_of_supervisors_district_5', names(d5.subset))], center=TRUE, scale=TRUE, tol=.1)
pca.df <- as.data.frame(pca$x)
pca.df$board_of_supervisors_district_5_dean_preston <- d5.subset$board_of_supervisors_district_5_dean_preston
pca.cor <- cor.flat(pca.df)
pca.cor <- pca.cor[grepl('dean_preston', pca.cor$First.Variable)|grepl('dean_preston', pca.cor$Second.Variable), ]
pca.cor[grepl('dean_preston', pca.cor$Second.Variable), c('First.Variable', 'Second.Variable')] <- pca.cor[grepl('dean_preston', pca.cor$Second.Variable), c('Second.Variable', 'First.Variable')]
pca.cor
```

Now let's just try a multiple linear regression on the top couple:

```{r echo=FALSE}
mean.residuals <- c()
fits <- list()
ns <- 1:10
for(n in ns){
  pcs <- as.character(pca.cor[1:n, 'Second.Variable'])
  pca.subset <- pca.df[, c('board_of_supervisors_district_5_dean_preston', pcs)]
  fit <- lm(board_of_supervisors_district_5_dean_preston ~ ., data=pca.subset)
  mean.residuals <- c(mean.residuals, mean(abs(fit$residuals)))
  fits[[n]] <- fit
}

do.call(anova, fits)

```

So even for something simple like multiple linear regression we don't need to include more than 9 PCs. Let's plot how adding more PCs affects the accuracy of our model:

```{r echo=FALSE}
p1 <- ggplot(data=data.frame(x=ns, y=mean.residuals), aes(x=x, y=y)) +
  geom_line() +
  xlab('Included principal components') +
  ylab('Mean residual magnitude') +
  scale_x_continuous(breaks=ns) +
  scale_y_continuous(breaks=seq(from=0, to=.04, by=.005))

p2 <- ggplot(data=data.frame(x=ns, y=sapply(fits, function(x) summary(x)$r.squared)), aes(x=x, y=y)) +
  geom_line() +
  xlab('Included principal components') +
  ylab('R^2') +
  scale_x_continuous(breaks=ns)

grid.arrange(p1, p2, top="PCA of Dean Preston vote by precinct")
```

In the interest of parsimony, let's restrict ourselves to the 3 most explanatory principle components, which in total explain `r percent(summary(fits[[3]])$r.squared)` of the variation in Dean's percent vote by precinct. Let's go through them one by one; I'll attempt to explain what I think they represent using my qualitative knowledge of local politics/the polarization around a given measure:

```{r echo=FALSE}
pca.names <- pca.cor[1:3, 'Second.Variable']
```

I'll now attempt to interpret these using a qualitative knowledge of city politics:

###`r pca.names[1]` : General "Conservativeness""
```{r echo=FALSE}
as.table(pca$rotation[, pca.names[1]][order(abs(pca$rotation[, pca.names[1]]), decreasing=TRUE)][1:15])
```
PC1 corresponds to something like **general "conservativness"** - things like keeping the death penalty, not raising taxes, maintaining the criminalization of marijuana, voting for the nefarious Prop Q which was essentially a symbolic middle finger to homeless people, and, depressingly, emphatically not voting for the one black candidate for the board of education. This one's a no-brainer, and it holds fairly well for all of the most important features in this PC.

###`r pca.names[2]`: Anti-Corporate/Anti-Establishment Sentiment
```{r echo=FALSE}
as.table(pca$rotation[, pca.names[2]][order(abs(pca$rotation[, pca.names[2]]), decreasing=TRUE)][1:15])
```
PC5 is a little harder to interpet, as there are some conflicting components here as far as cleavage along traditional left/right political lines. At first one might think this is the progressive democrat contingent, since voting for Preston Picus and not for Nancy Pelosi were the single most important features of this PC, but the ballot measures (and positive coefficient for Gary Johnson) complicate that interpretation. I suspect this principal component represents something more like **anti-establishment sentiment**. From the perspective of candidates, we see that this PC voted for Dean Preston, Preston Picus, Jill Stein, and Gary Johnson, and emphatically NOT for London Breed, Nancy Pelosi, or Hillary Clinton, which can pretty uncontroversially be classified as an insurgent/establishment binary. However, from the point of view of ballot measures, this PC also voted against school bonds and condoms in porn; and for restrictions on campaign contributions from lobbyists and transparency in the state legislature. I believe this feature can then be interpreted as distrust of the establishment, both political and corporate, and especially the intersection of the two. These may be small-government folks, some libertarians (as we see from the Gary Johnson coefficient,) or just people whose defining political ideology is less a left/right persepctive than it is an antagonistic stance towards what they may view as a corrupt political establishment.

*\*\*Note that the school board/community college members here were a little all over the place since you could vote for about half of the field, so I didn't belabor them, but they roughly match the above interpretation.*


###`r pca.names[3]`: Poorer, older folks
```{r echo=FALSE}
as.table(pca$rotation[, pca.names[3]][order(abs(pca$rotation[, pca.names[3]]), decreasing=TRUE)][1:15])
```
This one also isn't nearly as easy to interpret as PC1, but I suspect this is something like **older folks who fall towards the lower end of the socioeconomic spectrum**; given that this feature correlates the third most strongly with whether or not a precinct voted for Dean (and correlates negatively,) I suspect this may also be capturing some information about race. Without being too on the nose, given the makeup of District 5 and knowing a bit about which neighborhoods voted which way, it wouldn't be unreasonable to guess that this corresponds to something like older black folks. This PC voted for things like condoms in porn and transparency in government, and against the anti-homelessness prop Q, but the defining characteristic of this PC was that it voted strongly for affordable housing at every opportunity. It also voted for Nancy Pelosi and London Breed over Preston Picus and Dean Preston, which leads me to believe that this is older, socially moderate folks.

A few things in this are hard to interpret, most notably the rejection of the tree ordinance and the BART bond. I can't explain the latter at all really, and I recall there being some very neighborhood-specific antipathy towards the tree ordinance, but I don't know where. The school board folks are a little weird here too, but Rob Geller in particular got such a small percent of the vote that it could just be a few anomalous precincts - this is only a population of 67 precincts, after all.

