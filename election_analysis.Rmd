---
title: "Analysis of the November 2016 San Francisco Election Results"
author: "Charles Davis"
output:
  github_document: default
  html_document: default
  html_notebook: default
  pdf_document: default
---

# Introduction

As a San Francisco resident, data scientist, and highly political person, I've endeavored to conduct some analysis of the city's recent election results. Most Americans were shocked in some way by the November 2016 elections; essentially nobody thought Donald Trump would be president, and there were plenty of fairly surprising result to be found in California and San Francisco. As one of a number of possible examples, the fact that the death penalty was not just maintained but expedited was certainly a surprise to me and to everyone I knew; I don't know that I ever saw any actual polling on this issue, but I had certainly assumed, given the ostensibly liberal character of California, that it would be repealed in a landslide.

Understanding the roots of these upsets must be paramount for any political project, electoral or otherwise. In the course of this analysis, I hope to tease out some less obvious conclusions about these results; certainly some neighborhoods have different political character than others, but approaching this with an eye to nuance beyond the left/right binary will make it far easier to pinpoint exactly what happened. I hope to use this data to infer as much as possible about the different kinds of San Francisco voters, both out of a deep, visceral curiosity and in the hopes of perhaps eventually using these conslusions to more effectively engage folks in direct and electoral political action.

I definitely have a deep "academic" interest in this material; that being said, I volunteered extensively with Dean Preston's campaign for supervisor of District 5, which naturally partly informs my motivation to look into this data. Self-fulfillment notwithstanding, my work with the campaign has given me a uniquely intimate view into the District 5 supervisor race, so I'll focus much of my analysis on it not only because it is the race in which I'm most interested, but because it is the race in which I have the most non-data expertise.

##Data
The data to be analyzed in this project is precinct-level voting data from the San Francisco November 2016 election.

###Sources
See the [readme](./README.md) for the sources of the data. All original data is contained in the [source data](./data/source_data/) directory of this respository.

###Pre-Processing
The .csv files used to conduct this analysis are processed from the [source data](./data/source_data/) into the [actual files used](./data/derived_data/) as part of this [IPython notebook](./geodatabase_from_source_data.ipynb).

```{r setup, echo=FALSE, warning=FALSE, message=FALSE}
rm(list=ls())
require(scales)
require(ggplot2)
require(gridExtra)
require(knitr)
```

```{r echo=FALSE}

exclusions <- c()

raw.df <- NULL
measure.names <- c()
for(f in list.files('./data/derived_data')){
  # For now we only want to parse the files that are election data that is not explicitly excluded above
  if(startsWith(f, 'precinct_summary_') & !(f %in% exclusions)){
    df <- read.csv(paste('./data/derived_data/', f, sep=''))
    prefix <- tolower(strsplit(f, '-')[[1]][2])
    prefix <- gsub("^[[:space:]]", "", prefix)  # Strip leading whitespace
    prefix <- gsub("[[:space:]]", "_", prefix)  # Replace spaces with underscores
    prefix <- gsub("[^[:alnum:]&^\\_]", "", prefix)  # Drop non-alphanumeric characters (except underscores)
    prefix <- substr(prefix, start=1, stop=nchar(prefix)-3)  # Drop the "csv" from the end
    measure.names <- c(measure.names, prefix)
    names(df)[names(df)!='precinctid'] <- paste(prefix, names(df)[names(df)!='precinctid'], sep='_')
    if(is.null(raw.df)){
      raw.df <- df
    }
    else{
      raw.df <- merge(raw.df, df, by='precinctid', all.x=TRUE)
    }
  }
}
```

## Feature creation

Now on to feature creation and cleaning. We don't care about over vote (votes where too many choices were filled in, and so were disregarded,) on its own, so we'll certainly drop that. We'll drop under votes as well; at least as far as I understand it, under votes are still counted towards the candidates that were filled in, but the number of ballots that didn't fill out the maximum number of candidates isn't very meaningful to us on its own. For the ballot measures, we'll normalize the yes votes as yes/(yes+no), which we'll call "yes_of_accepted", and drop the no votes. For races with people, we'll drop write-in since I'd be shocked if that had any useful information, and then normalize the rest of the votes as votes_for_candidate/ballots_cast. For every measure we'll also create a feature calculated as ballots_cast/registration, called which we'll call "turnout."


```{r echo=FALSE}
over.vote.percents <- c()
for (measure.name in measure.names){
  voters <- raw.df[!is.na(raw.df[, paste(measure.name, 'over_vote', sep='_')]),]
  over.vote <- voters[, paste(measure.name, 'over_vote', sep='_')]
  ballots.cast <- voters[, paste(measure.name, 'ballots_cast', sep='_')]
  over.vote.percents <- c(over.vote.percents, sum(over.vote) / sum(ballots.cast))
}
# We need to exclude State Senator in District 13, because no one in SF voted in it:
over.vote.percents <- over.vote.percents[!is.na(over.vote.percents)]
```

As far as dropping over votes, we should still check what percentage of the votes were over votes just to sleep more soundly; this number turns out to be `r percent(mean(over.vote.percents))` of the ballots cast for a measure were over votes, so we don't need to worry too much about their interpretation.

```{r echo=FALSE}
features.df <- raw.df
for (measure.name in measure.names){
  features <- names(features.df)[grepl(measure.name, names(features.df))]
  if(paste(measure.name, 'yes', sep='_') %in% features){
    features.df[, paste(measure.name, 'yes_of_accepted', sep='_')] <- (
      features.df[, paste(measure.name, 'yes', sep='_')] / (
        features.df[, paste(measure.name, 'yes', sep='_')] + features.df[, paste(measure.name, 'no', sep='_')]
        )
      )
  }
  else{
    for (feature in features){
      if(!(
        endsWith(feature, 'under_vote') |
        endsWith(feature, 'over_vote') |
        endsWith(feature, 'ballots_cast') |
        endsWith(feature, 'registration')
      )){
        features.df[, feature] <- features.df[, feature] / features.df[, paste(measure.name, 'ballots_cast', sep='_')]
      }
    }
  }
  features.df[, paste(measure.name, 'turnout', sep='_')] <- (
    features.df[, paste(measure.name, 'ballots_cast', sep='_')] / features.df[, paste(measure.name, 'registration', sep='_')]
    )
  features.df <- features.df[, !names(features.df) %in% c(
    paste(measure.name, 'no', sep='_'),
    paste(measure.name, 'yes', sep='_'),
    paste(measure.name, 'writein', sep='_'),
    paste(measure.name, 'under_vote', sep='_'),
    paste(measure.name, 'over_vote', sep='_'),
    paste(measure.name, 'ballots_cast', sep='_'),
    paste(measure.name, 'precincts', sep='_'),
    paste(measure.name, 'registration', sep='_')
  )]
}
```

# Understanding the District 5 Supervisor Race

A race near and dear to me. Let's start by just checking out what the Dean vote percent correlates with:

```{r echo=FALSE}
# Filter to D5
d5 <- features.df[!is.na(features.df$board_of_supervisors_district_5_turnout),]
d5 <- d5[, !apply(is.na(d5), 2, any)]
d5.subset <- d5[, sapply(names(d5), function(x) !endsWith(x, 'turnout') & x != 'precinctid')]
```

```{r echo=FALSE}
cor.flat <- function(df){
  cor.matrix <- cor(df)
  diag(cor.matrix) <- 0
  cor.matrix[lower.tri(cor.matrix)] <- 0
  cor.matrix <- as.data.frame(as.table(cor.matrix))
  names(cor.matrix) <- c("First.Variable", "Second.Variable","Correlation")
  cor.matrix[order(abs(cor.matrix$Correlation),decreasing=T),]
}

dean.cor <- cor.flat(d5.subset)
dean.cor <- dean.cor[(grepl('dean_preston', dean.cor$First.Variable))|(grepl('dean_preston', dean.cor$Second.Variable)),]
dean.cor[!grepl('dean_preston', dean.cor$First.Variable), c('First.Variable', 'Second.Variable')] <- dean.cor[!grepl('dean_preston', dean.cor$First.Variable), c('Second.Variable', 'First.Variable')]
dean.cor <- dean.cor[, names(dean.cor) != 'First.Variable']
kable(head(dean.cor, 15))
```

Nothing too surprising or counterintuitive in the top couple - London correlating against Dean so strongly obviously makes sense, and, as I've noted elsewhere, a precinct's choice of supervisor is most strongly correlated with whether or not it wanted mandatory condom use in porn (State Prop 60), hilariously enough. Let's look at plots of the top 4 (excluding London):

```{r echo=FALSE}
# Let's drop London, since that's useless
plot.data <- d5.subset[, c(as.character(dean.cor[2:5, 'Second.Variable']), 'board_of_supervisors_district_5_dean_preston')]
plots <- lapply(colnames(plot.data)[!grepl('dean_preston', colnames(plot.data))], function(column) {
  rs <- percent(summary(lm(plot.data[, 'board_of_supervisors_district_5_dean_preston']~plot.data[,column]))$r.squared)
  ggplot(data=plot.data, aes_string(x=column, y='board_of_supervisors_district_5_dean_preston')) +
    geom_point() +
    stat_smooth(method="lm") + ylab('% Dean of Accepted') +
    annotate("text", x=-Inf, y=-Inf, vjust=0, hjust=0, label=paste('R^2=', rs, sep=''))
})
do.call(grid.arrange, list(grobs=plots, ncol=2, top="Strongest Dean Correlations"))
```

##Breaking it down: PCA

Doing a series of linear regressions against other ballot measures doesn't get us very far in understanding the factors underlying the results of the District 5 supervisor race. The State Prop 60 (mandatory condom use in porn) result correlating so strongly with the Dean vote hilarious and weird, but not super surprising - there's probably a latent age variable underlying it. Tom Temprano essentially ran with Dean, basically every voter guide that endorsed Dean also endorsed Jane Kim, and, while I wouldn't have guessed Prop N (non-citizen voting in school board elections) would be number 4, it also obviously isn't suprising when viewed from the traditional left/right political paradigm.

We want to essentially understand the latent variables underlying the election results. The way to get to latent variables, in a formal sense, would be something like factor analysis or partial least squares regression. However, we're going to use principal components analysis. Why? I'm more familiar with it, and it almost always gives a very similar result to factor analysis. Perhaps most importantly, though, principal components are by definition orthogonal, whereas latent variables are not necessarily orthogonal. I'll explain why I think that's a desirable property for this interpretation after we calculate the principal components.

Our approach here will essentially be a home-cooked version of principal components regression:

* Do dimensionality reduction using PCA
* Find the principal components that correlate most strongly with some measure in which we are interested (first, the district 5 supervisor race)
* Check how much these of the variance in our response (Dean) the PCs explain when used in a multiple linear regression, and choose how many to keep for the sake of parsimony
* Test whether those same principal components also explain a good chunk of the variance in other measures where there's a clear progressive/moderate split

As mentioned above, we'll first try this on the D5 supervisor race because I'm personally attached to it and I wanna know what happened, damnit!

```{r echo=FALSE}
# Set tolerance to .1 to cut out the most useless components
pca <- prcomp(d5.subset[!grepl('board_of_supervisors_district_5', names(d5.subset))], center=TRUE, scale=TRUE, tol=.1)
pca.df <- as.data.frame(pca$x)
pca.df$board_of_supervisors_district_5_dean_preston <- d5.subset$board_of_supervisors_district_5_dean_preston
pca.cor <- cor.flat(pca.df)
pca.cor <- pca.cor[grepl('dean_preston', pca.cor$First.Variable)|grepl('dean_preston', pca.cor$Second.Variable), ]
pca.cor[grepl('dean_preston', pca.cor$Second.Variable), c('First.Variable', 'Second.Variable')] <- pca.cor[grepl('dean_preston', pca.cor$Second.Variable), c('Second.Variable', 'First.Variable')]
kable(head(pca.cor, 10))
```

Now let's just try a multiple linear regression on the top couple:

```{r echo=FALSE}
mean.residuals <- c()
fits <- list()
ns <- 1:10
for(n in ns){
  pcs <- as.character(pca.cor[1:n, 'Second.Variable'])
  pca.subset <- pca.df[, c('board_of_supervisors_district_5_dean_preston', pcs)]
  fit <- lm(board_of_supervisors_district_5_dean_preston ~ ., data=pca.subset)
  mean.residuals <- c(mean.residuals, mean(abs(fit$residuals)))
  fits[[n]] <- fit
}

do.call(anova, fits)

```

So even for something simple like multiple linear regression we don't need to include more than 9 PCs. Let's plot how adding more PCs affects the accuracy of our model:

```{r echo=FALSE}
p1 <- ggplot(data=data.frame(x=ns, y=mean.residuals), aes(x=x, y=y)) +
  geom_line() +
  xlab('Included principal components') +
  ylab('Mean residual magnitude') +
  scale_x_continuous(breaks=ns) +
  scale_y_continuous(breaks=seq(from=0, to=.04, by=.005))

p2 <- ggplot(data=data.frame(x=ns, y=sapply(fits, function(x) summary(x)$r.squared)), aes(x=x, y=y)) +
  geom_line() +
  xlab('Included principal components') +
  ylab('R^2') +
  scale_x_continuous(breaks=ns)

grid.arrange(p1, p2, top="PCA of Dean Preston vote by precinct")
```

In the interest of parsimony, let's restrict ourselves to the 3 most explanatory principle components, which in total explain `r percent(summary(fits[[3]])$r.squared)` of the variation in Dean's percent vote by precinct. Let's go through them one by one; I'll attempt to explain what I think they represent using my qualitative knowledge of local politics/the polarization around a given measure:

```{r echo=FALSE}
pca.names <- pca.cor[1:3, 'Second.Variable']
```

###`r pca.names[1]` : General "Conservativeness"
```{r echo=FALSE}
d <- pca$rotation[, pca.names[1]][order(abs(pca$rotation[, pca.names[1]]), decreasing=TRUE)][1:15]
kable(data.frame(measure.name=names(d), rotation.coefficient=unname(d)))
```

PC1 corresponds to something like **general "conservativness"** - things like keeping the death penalty, not raising taxes, maintaining the criminalization of marijuana, voting for the nefarious Prop Q which was essentially a symbolic middle finger to homeless people, and, depressingly, emphatically not voting for the one black candidate for the board of education. This one's a no-brainer, and it holds fairly well for all of the most important features in this PC.

###`r pca.names[2]`: Anti-Corporate/Anti-Establishment Sentiment
```{r echo=FALSE}
d <- pca$rotation[, pca.names[2]][order(abs(pca$rotation[, pca.names[2]]), decreasing=TRUE)][1:15]
kable(data.frame(measure.name=names(d), rotation.coefficient=unname(d)))
```

PC5 is a little harder to interpet, as there are some conflicting components here as far as cleavage along traditional left/right political lines. At first one might think this is the progressive democrat contingent, since voting for Preston Picus and not for Nancy Pelosi were the single most important features of this PC, but the ballot measures (and positive coefficient for Gary Johnson) complicate that interpretation. I suspect this principal component represents something more like **anti-establishment sentiment**. From the perspective of candidates, we see that this PC voted for Dean Preston, Preston Picus, Jill Stein, and Gary Johnson, and emphatically NOT for London Breed, Nancy Pelosi, or Hillary Clinton, which can pretty uncontroversially be classified as an insurgent/establishment binary. However, from the point of view of ballot measures, this PC also voted against school bonds and condoms in porn; and for restrictions on campaign contributions from lobbyists and transparency in the state legislature. I believe this feature can then be interpreted as distrust of the establishment, both political and corporate, and especially the intersection of the two. These may be small-government folks, some libertarians (as we see from the Gary Johnson coefficient,) or just people whose defining political ideology is less a left/right persepctive than it is an antagonistic stance towards what they may view as a corrupt political establishment.

*&ast;&ast;Note that the school board/community college members here were a little all over the place since you could vote for about half of the field, so I didn't belabor them, but they roughly match the above interpretation.*


###`r pca.names[3]`: Poorer, older folks
```{r echo=FALSE}
d <- pca$rotation[, pca.names[3]][order(abs(pca$rotation[, pca.names[3]]), decreasing=TRUE)][1:15]
kable(data.frame(measure.name=names(d), rotation.coefficient=unname(d)))
```

This one also isn't nearly as easy to interpret as PC1, but I suspect this is something like **older, poorer, more socially moderate folks**. Coupled with the fact that this feature correlates the third most strongly with whether or not a precinct voted for Dean (and correlates negatively,) I suspect this may also be capturing some information about race. Without being too on the nose, given the makeup of District 5 and knowing a bit about which neighborhoods voted which way, it wouldn't be unreasonable to guess that this corresponds to something like older black folks. This PC voted for things like condoms in porn and transparency in government, and against the anti-homelessness prop Q, but the defining characteristic of this PC was that it voted strongly for affordable housing at every opportunity. It also voted for Nancy Pelosi and London Breed over Preston Picus and Dean Preston, which leads me to believe that this is older, socially moderate folks.

A few things in this are hard to interpret, most notably the rejection of the tree ordinance and the BART bond. I can't explain the latter at all really, and I recall there being some very neighborhood-specific antipathy towards the tree ordinance, but I wouldn't feel comfortable hazarding an interpretation of it. The school board folks are a little weird here too, but Rob Geller in particular got such a small percent of the vote that it could just be a few anomalous precincts - this is only a population of 67 precincts, after all.

###Why Orthogonality is Good
I mentioned earlier that I actually think orthogonality is a desirable property for the features we're creating/interpreting. PLSR and FA create features that can usually explain the same amount of variance as PCA with slightly fewer features, which is certainly an advantage, but orthogonality means that we can interpet the principal components *totally independently of each other*; e.g., varying PC3 would tell us how much more likely someone is to vote for Dean based on their anti-authoritarian impulses *while holding conservatism and status as elderly poor constant*. If these vectors weren't orthogonal, that wouldn't (necessarily) be the case. Practically, this means that we couldn't, e.g., measure a precinct's anti-authoritarian impulse as distinct from its conservatism; these two are probably somehow related, and unless the vectors we create to represent them are orthogonal, we can't separate them out completely.

